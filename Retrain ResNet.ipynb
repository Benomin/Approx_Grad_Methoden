{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-25T09:58:42.784418Z",
     "start_time": "2025-08-25T09:58:42.783430Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T09:58:43.887648Z",
     "start_time": "2025-08-25T09:58:42.861772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import shutil\n",
    "from approx_attributes import *\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from captum.attr import InputXGradient,IntegratedGradients,Saliency\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ],
   "id": "f81ed21bce176fdb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+rocm6.4\n",
      "0.23.0+rocm6.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benomin/PycharmProjects/BA-Approoximation-Feature-Attribution/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T09:58:44.649002Z",
     "start_time": "2025-08-25T09:58:43.894108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "cifar_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(cifar_trainset, batch_size=1, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(cifar_testset, batch_size=1, shuffle=False)\n",
    "\n",
    "dataset = test_loader.dataset\n",
    "cifar10_labels = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\"\n",
    "}"
   ],
   "id": "541bdcdf736c4b5a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T09:58:45.266808Z",
     "start_time": "2025-08-25T09:58:44.656055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "\n",
    "# Wähle einen zufälligen Index\n",
    "idx = np.random.randint(0, len(dataset) - 1)\n",
    "\n",
    "# Hole das Bild und Label\n",
    "img, label = dataset[idx]"
   ],
   "id": "86b43e57ea0eaca4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/benomin/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/benomin/PycharmProjects/BA-Approoximation-Feature-Attribution/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/benomin/PycharmProjects/BA-Approoximation-Feature-Attribution/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T22:22:09.854854Z",
     "start_time": "2025-08-25T14:12:40.022935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False\n",
    "\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.maxpool = nn.Identity()  # ersetzt das MaxPooling durch \"nichts\"\n",
    "\n",
    "num_classes = 10\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "num_classes = 10\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\"\"\""
   ],
   "id": "5aaf5a56ca216931",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 2.7972\n",
      "Epoch [2/20], Loss: 2.5278\n",
      "Epoch [3/20], Loss: 2.4017\n",
      "Epoch [4/20], Loss: 2.3067\n",
      "Epoch [5/20], Loss: 2.2546\n",
      "Epoch [6/20], Loss: 2.2181\n",
      "Epoch [7/20], Loss: 2.1952\n",
      "Epoch [8/20], Loss: 2.1647\n",
      "Epoch [9/20], Loss: 2.1484\n",
      "Epoch [10/20], Loss: 2.1423\n",
      "Epoch [11/20], Loss: 2.1220\n",
      "Epoch [12/20], Loss: 2.1104\n",
      "Epoch [13/20], Loss: 2.0965\n",
      "Epoch [14/20], Loss: 2.0926\n",
      "Epoch [15/20], Loss: 2.0859\n",
      "Epoch [16/20], Loss: 2.0818\n",
      "Epoch [17/20], Loss: 2.0803\n",
      "Epoch [18/20], Loss: 2.0701\n",
      "Epoch [19/20], Loss: 2.0729\n",
      "Epoch [20/20], Loss: 2.0585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nnum_classes = 10\\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\\n\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = optim.Adam(model.parameters(), lr=0.001)\\n\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\nmodel = model.to(device)\\n\\nnum_epochs = 5\\n\\nfor epoch in range(num_epochs):\\n    model.train()\\n    running_loss = 0.0\\n    for images, labels in train_loader:\\n        images, labels = images.to(device), labels.to(device)\\n\\n        optimizer.zero_grad()\\n        outputs = model(images)\\n        loss = criterion(outputs, labels)\\n        loss.backward()\\n        optimizer.step()\\n\\n        running_loss += loss.item()\\n\\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T23:04:56.711546Z",
     "start_time": "2025-08-25T23:02:13.489754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ],
   "id": "5f8c413128b83ff8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 15.61%\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T23:04:56.978054Z",
     "start_time": "2025-08-25T23:04:56.766288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.save(model, \"resnet152_cifar10_32x32_epoch20.pth\")\n",
    "\n",
    "# Laden\n",
    "\"\"\"\n",
    "model = torch.load(\"resnet18_cifar10_full.pth\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\"\"\""
   ],
   "id": "bf5d70ce1163ede3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = torch.load(\"resnet18_cifar10_full.pth\")\\nmodel.to(device)\\nmodel.eval()\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
